{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import spacy\n",
    "import unidecode\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import datetime\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './app/data/6tOKJU9WevI.json'\n",
    "\n",
    "df = pd.read_json(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['authorDisplayName']\n",
    "del df['authorProfileImageUrl']\n",
    "del df['authorChannelUrl']\n",
    "del df['canRate']\n",
    "del df['viewerRating']\n",
    "del df['authorChannelId']\n",
    "del df['updatedAt']\n",
    "del df['textDisplay']\n",
    "del df['likeCount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date(text):\n",
    "    dateText = text.split('T')[0]\n",
    "    return datetime.datetime.strptime(dateText, \"%Y-%m-%d\").date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date\"] = df[\"publishedAt\"].apply(parse_date)\n",
    "del df['publishedAt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_newline(text):\n",
    "    text = text.replace('\\n', '. ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"textOriginal\"] = df[\"textOriginal\"].apply(replace_newline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentences'] = df['textOriginal'].apply(sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numbers(text):\n",
    " text = re.sub('\\w*\\d\\w*', '', text)\n",
    " return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid_obj = SentimentIntensityAnalyzer()\n",
    "def score_sentiment(sentences):\n",
    "    compounds = []\n",
    "    intensities = []\n",
    "    for sentence in sentences:\n",
    "        sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "        if sentiment_dict['compound'] >= 0.05 :\n",
    "            intensities.append(sentiment_dict[\"pos\"])\n",
    "        elif sentiment_dict['compound'] <= - 0.05 :\n",
    "            intensities.append(sentiment_dict[\"neg\"])\n",
    "        compounds.append(sentiment_dict['compound'])\n",
    "\n",
    "    comment_compound = np.average(compounds)\n",
    "    intesity_average = np.average(intensities)\n",
    "    \n",
    "    if comment_compound >= 0.05:\n",
    "        sentiment = \"Positive\"\n",
    "    elif comment_compound <= -0.05:\n",
    "        sentiment = \"Negative\"\n",
    "    else:\n",
    "        sentiment = \"Neutral\"\n",
    "\n",
    "    if np.isnan(intesity_average):\n",
    "        intesity_average = 0.0\n",
    "    \n",
    "    return sentiment, intesity_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'], df['intensity'] = zip(*df['sentences'].apply(score_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"intensity\"] > 0.75].groupby('sentiment').intensity.count().plot(kind=\"bar\", xlabel=\"Sentiment\", ylabel=\"Number of high intensity comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Positive\", \"Negative\", \"Neutral\"]\n",
    "sum = df['sentiment'].count()\n",
    "neg_count = df[df['sentiment'] == 'Negative']['sentiment'].count()\n",
    "neu_count = df[df['sentiment'] == 'Neutral']['sentiment'].count()\n",
    "pos_count = df[df['sentiment'] == 'Positive']['sentiment'].count()\n",
    "sizes = [pos_count/sum, neg_count/sum, neu_count/sum]\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_accented_chars(text):\n",
    "    text = unidecode.unidecode(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_punctuation(text):\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = str(text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "STOPWORDS = nlp.Defaults.stop_words\n",
    "STOPWORDS.add('like')\n",
    "def remove_stopwords(text):\n",
    "    tokenized_text = text.split(' ')\n",
    "    return ' '.join([w for w in tokenized_text if not w in STOPWORDS and len(w) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    doc = nlp(text)\n",
    "    return ' '.join([w.lemma_ for w in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_adjectives_adverbs_verbs(text):\n",
    "        return ' '.join(word.text for word in nlp(text) if not (word.pos_ == 'VERB' or word.pos_ == 'ADV'  or word.pos_ == 'ADJ') and not (word.text == \"nt\" or word.text == \"ve\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleanSentence'] = df['textOriginal'].str.lower()\n",
    "df['cleanSentence'] = df['cleanSentence'].apply(clean_punctuation)\n",
    "df['cleanSentence'] = df['cleanSentence'].apply(remove_adjectives_adverbs_verbs)\n",
    "df['cleanSentence'] = df['cleanSentence'].apply(remove_stopwords)\n",
    "df['cleanSentence'] = df['cleanSentence'].apply(lemmatization)\n",
    "df['cleanSentence'].replace('', float(\"NaN\"), inplace=True)\n",
    "df.dropna(subset=['cleanSentence'], inplace=True)\n",
    "df['keywords'] = df['cleanSentence'].apply(word_tokenize)\n",
    "del df['cleanSentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_token_array(values):\n",
    "    tokens = []\n",
    "    for tokenizedSentece in values:\n",
    "        for token in tokenizedSentece:\n",
    "            tokens.append(token)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_frequency_map(tokens):\n",
    "    fdist = nltk.FreqDist(tokens)\n",
    "    return fdist.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tokens = create_token_array(df[df['sentiment'] == 'Positive']['keywords'].values)\n",
    "neg_tokens = create_token_array(df[df['sentiment'] == 'Negative']['keywords'].values)\n",
    "neu_tokens = create_token_array(df[df['sentiment'] == 'Neutral']['keywords'].values)\n",
    "pos_bigrams = nltk.bigrams(pos_tokens)\n",
    "neg_bigrams = nltk.bigrams(neg_tokens)\n",
    "neu_bigrams = nltk.bigrams(neu_tokens)\n",
    "pos_freq = create_frequency_map(pos_tokens)\n",
    "neg_freq = create_frequency_map(neg_tokens)\n",
    "neu_freq = create_frequency_map(neu_tokens)\n",
    "pos_bigram_freq = create_frequency_map(pos_bigrams)\n",
    "neg_bigram_freq = create_frequency_map(neg_bigrams)\n",
    "neu_bigram_freq = create_frequency_map(neu_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_sentiment(pos_freq, neg_freq, neu_freq):\n",
    "    result = dict()\n",
    "    for k, v in pos_freq:\n",
    "        result[k] = [v, 0, 0]\n",
    "    for k,v in neu_freq:\n",
    "        try:\n",
    "            result[k][1] = v\n",
    "        except:\n",
    "            result[k] = [0, v, 0]\n",
    "    for k,v in neg_freq:\n",
    "        try:\n",
    "            result[k][2] = v\n",
    "        except:\n",
    "            result[k] = [0, 0, v]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict_to_dataframe(dict):\n",
    "    df = pd.DataFrame(dict.items(), columns=['word','frequencies'])\n",
    "    df[['positive', 'neutral', 'negative']] = pd.DataFrame(df['frequencies'].tolist(), index=df.index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bicontext_sentiment_dict = context_sentiment(pos_bigram_freq, neg_bigram_freq, neu_bigram_freq)\n",
    "df_bigram = convert_dict_to_dataframe(bicontext_sentiment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_sentiment_dict = context_sentiment(pos_freq, neg_freq, neu_freq)\n",
    "df_words = convert_dict_to_dataframe(context_sentiment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(frequencies):\n",
    "    v = np.array(frequencies)\n",
    "    v = v * (1 / np.linalg.norm(v))\n",
    "    return v[0] * 1 + v[1] * 0.01 + v[2] * (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigram['score'] = df_bigram['frequencies'].apply(normalize)\n",
    "df_words['score'] = df_words['frequencies'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_context_sentiment(compound):\n",
    "    if compound == 0.01:\n",
    "        result = \"Neutral\"\n",
    "    elif compound > 0.5:\n",
    "        result = \"Mostly positive\"\n",
    "    elif compound > 0.1:\n",
    "        result = \"Slightly positive\"\n",
    "    elif compound > -0.1:\n",
    "        result = \"Controversial\"\n",
    "    elif compound > -0.5:\n",
    "        result = \"Slightly negative\"\n",
    "    else:\n",
    "        result = \"Mostly negative\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigram['context_sentiment'] = df_bigram['score'].apply(score_context_sentiment)\n",
    "df_words['context_sentiment'] = df_words['score'].apply(score_context_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words.groupby(\"context_sentiment\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigram.groupby(\"context_sentiment\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "df[['date', 'sentiment']][df['sentiment'] == 'Positive'].groupby('date').count().plot(ax=ax, color='green')\n",
    "df[['date', 'sentiment']][df['sentiment'] == 'Negative'].groupby('date').count().plot(ax=ax, color='red')\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Number of comments posted\")\n",
    "ax.legend(['Positive', 'Negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['sentiment'] == 'Positive') | (df['sentiment'] == 'Negative')].groupby('date').intensity.apply().mean().plot(xticks=pd.date_range(df.groupby('date').date.min().min(), df.groupby('date').date.max().max(), periods=7), xlabel=\"Date of comments posted\", ylabel = \"Average intensity of comments\", yticks=np.arange(0, 1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['sentiment'] == 'Positive') | (df['sentiment'] == 'Negative')].groupby('date').filter(lambda x: x['intensity'].count() > 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "df.loc[(df['sentiment'] == 'Positive') | (df['sentiment'] == 'Negative')].groupby('date').filter(lambda x: x['intensity'].count() > 1).groupby('date').intensity.min().plot(xlabel=\"Date of comments posted\", ylabel = \"Average intensity of comments\", yticks=np.arange(0, 1, 0.1))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db0a5040aede52cb1e1b34d15ccf165a7655be9619cda6cfa8a37490a76c655c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
